{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa43e000-c0b3-4cf4-bbc2-316e2cfe9fad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 1: Enterprise Data Model Design\n",
    "### Key Entities and Relationships\n",
    "1. **Customer**:\n",
    "   - **Attributes**: CustomerID (Primary Key), Name, Email, RegistrationDate, CustomerType (e.g., regular, premium, etc.), Country, LastActiveDate.\n",
    "   - **Purpose**: Captures the basic profile and segmentation information of each customer.\n",
    "   - **ML Usage**:\n",
    "Helps in customer segmentation for personalized recommendations.\n",
    "Tracks retention rates, enabling churn prediction models.\n",
    "\n",
    "2. **Transaction**:\n",
    "   - **Attributes**: TransactionID (Primary Key), CustomerID (Foreign Key to Customer), ProductID, Date, Amount, PaymentMethod, TransactionStatus (e.g., Completed, Cancelled).\n",
    "   - **Purpose**: Records every transaction a customer makes.\n",
    "   - **ML Usage**:\n",
    "Provides insights into purchasing behavior, e.g., average order value, purchase frequency.\n",
    "Enables prediction of lifetime value (CLV) based on transaction trends.\n",
    "\n",
    "3. **Interaction**:\n",
    "\n",
    "   - **Attributes**: InteractionID (Primary Key), CustomerID (Foreign Key to Customer), InteractionType (e.g., view, click, add-to-cart), Timestamp, Page, Source (e.g., mobile app, website), Metadata.\n",
    "   - **Purpose**: Captures granular details about how customers interact with the platform.\n",
    "   - **ML Usage**: Tracks customer journeys and engagement trends.Helps in building features such as interaction-to-purchase conversion rates and session behavior patterns.\n",
    "\n",
    "4. **Product**:\n",
    "   - **Attributes**: ProductID (Primary Key), Category, Price, StockAvailability.\n",
    "   - **Purpose**: Stores product information.\n",
    "   - **ML Usage**:Enables recommendation models by combining product attributes with transaction and interaction data.\n",
    "\n",
    "### Data Model Diagram + pipeline detail\n",
    "![](https://dev232image.blob.core.windows.net/devimages/detailed_pipeline.png)\n",
    "\n",
    "\n",
    "###ML Usecases:\n",
    "\n",
    "**Churn Prediction**\n",
    "\n",
    "- Combine Customer and Interaction data to track activity levels.\n",
    "- Use Transaction data to observe the gap between purchases.\n",
    "\n",
    "- ML Features:\n",
    "  - DaysSinceLastPurchase: From Transaction data.\n",
    "  - ActivityRate: From Interaction data (total interactions divided by the time since registration).\n",
    "\n",
    "**Customer Segmentation**\n",
    "\n",
    "- Utilize Customer and Transaction data to segment customers by spending patterns.\n",
    "- Combine with Interaction data to determine engagement.\n",
    "- ML Features:\n",
    "   - AverageOrderValue: From Transaction data.\n",
    "   - SessionDuration: From Interaction data.\n",
    "\n",
    "**Personalized Recommendations**\n",
    "\n",
    "- Use Transaction and Product data to identify frequently bought products.\n",
    "- Combine with Interaction data to observe viewing habits.\n",
    "- ML Features:\n",
    "   - ProductAffinity: Percentage of interactions leading to purchases for each product.\n",
    "   - CategoryPreferences: Most frequently purchased product categories.\n",
    "\n",
    "**Lifetime Value (CLV) Prediction**\n",
    "\n",
    "- Combine Customer, Transaction, and Interaction data to assess lifetime value.\n",
    "- ML Features:\n",
    "   - TotalSpend: Sum of all transactions.\n",
    "   - InteractionToPurchaseRatio: Ratio of interactions to completed purchases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1658be74-2aa0-4fa4-b2f3-11f5b9549ca9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 2: Pipeline Architecture Diagram\n",
    "![pipeline](https://dev232image.blob.core.windows.net/devimages/pipeline_diagram.png)\n",
    "\n",
    "###Detailed Pipeline Workflow\n",
    "![](https://dev232image.blob.core.windows.net/devimages/detailed_pipeline.png)\n",
    "1. **Data Ingestion**:\n",
    "\n",
    "   - Batch Ingestion: Utilize Databricksâ€™ Autoloader for schema inference and efficient loading.\n",
    "   Ingest files from cloud storage (S3, Azure Data Lake) into the Bronze layer.\n",
    "   - Streaming Ingestion:\n",
    "   Use Structured Streaming to handle real-time data (e.g., events from Kafka).\n",
    "\n",
    "2. **Schema Enforcement and Validation**:\n",
    "\n",
    "   - Enforce strict schemas during ingestion to avoid malformed data downstream.\n",
    "   - Validate and log anomalies into a separate error table.\n",
    "\n",
    "3. **Transformation**:\n",
    "\n",
    "   - Use Spark SQL and Python for deduplication, null handling, and join operations in the Silver layer.\n",
    "   - Incremental updates using Delta Lake's MERGE INTO functionality.\n",
    "\n",
    "4. **Feature Engineering** :\n",
    "\n",
    "   - Aggregate data into pre-computed features like AverageOrderValue and SessionDuration.\n",
    "   - Store features in the Gold layer, ready for ML models or visualization.\n",
    "\n",
    "5. **Optimization** :\n",
    "   - Partition Gold tables by critical fields (e.g., CustomerID).\n",
    "   - Use Z-Ordering to cluster data and improve query performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4e873c2-9bbb-496e-8531-936915574fc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 3: Real-Time Data Integration Task\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bafc473b-4cad-4f43-b599-c3ef5383942e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"IngestionTask\").getOrCreate()\n",
    "\n",
    "# Following code defines a sample schema as per the requirement\n",
    "schema = StructType([\n",
    "    StructField(\"TransactionID\", StringType(), True),\n",
    "    StructField(\"CustomerID\", StringType(), True),\n",
    "    StructField(\"Amount\", FloatType(), True),\n",
    "    StructField(\"Timestamp\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Reading real-time data\n",
    "raw_stream = spark.readStream \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .schema(schema) \\\n",
    "    .load(\"/path/to/streaming/data\")\n",
    "\n",
    "# Data Validation and Deduplication as the mentioned task\n",
    "validated_stream = raw_stream.dropDuplicates([\"TransactionID\"]).na.fill({\"Amount\": 0})\n",
    "\n",
    "\n",
    "query = validated_stream.writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"checkpointLocation\", \"/path/to/checkpoint\") \\\n",
    "    .start(\"/path/to/delta/lake/bronze\")\n",
    "\n",
    "query.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6abd1f5a-8f91-4512-9428-bdf8c9a38c68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "489fe897-1b2e-4112-ab28-f5a0d8a0d6de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 4: Feature Engineering and ML Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45158a23-71e2-4a27-963b-e454f09ad333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, count, col\n",
    "\n",
    "# Read Bronze Data\n",
    "bronze_df = spark.read.format(\"delta\").load(\"/path/to/delta/lake/bronze\")\n",
    "\n",
    "# Feature Calculation: Purchase Frequency and Average Order Value\n",
    "features_df = bronze_df.groupBy(\"CustomerID\") \\\n",
    "    .agg(\n",
    "        count(\"TransactionID\").alias(\"PurchaseFrequency\"),\n",
    "        avg(\"Amount\").alias(\"AverageOrderValue\")\n",
    "    )\n",
    "\n",
    "# Optimize Delta Table\n",
    "features_df.write.format(\"delta\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"/path/to/delta/lake/gold\")\n",
    "\n",
    "# Enable Delta Optimizations\n",
    "spark.sql(\"OPTIMIZE '/path/to/delta/lake/gold' ZORDER BY (CustomerID)\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dataengineering_assessment_notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}